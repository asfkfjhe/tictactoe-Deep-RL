{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKa5KiDRgT-c"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "from gym import error, spaces, utils\n",
        "from gym.spaces import space\n",
        "from gym.utils import seeding\n",
        "\n",
        "import random\n",
        "\n",
        "class TicTacToeEnv(gym.Env):\n",
        "  metadata = {'render.modes': ['human']}\n",
        "\n",
        "  def __init__(self):\n",
        "    self.state = [\n",
        "        [\"-\",\"-\",\"-\"],\n",
        "        [\"-\",\"-\",\"-\"],\n",
        "        [\"-\",\"-\",\"-\"]\n",
        "        ]\n",
        "\n",
        "\n",
        "  def hash(self):\n",
        "    return \"\".join([item for sublist in self.state for item in sublist])\n",
        "\n",
        "\n",
        "  def available_actions(self):\n",
        "    return [i for i, x in enumerate(self.hash()) if x == \"-\"]\n",
        "\n",
        "  def available_states(self, player):\n",
        "    states = []\n",
        "    actions = self.available_actions()\n",
        "    for action in actions:\n",
        "      state_list = list(self.hash())\n",
        "      state_list[action] = player\n",
        "      state = \"\".join(state_list)\n",
        "      _, reward = self.check_done(state)\n",
        "      states.append((state, reward))\n",
        "    return states\n",
        "\n",
        "\n",
        "  def check_done(self, state):\n",
        "    winner = \"\"\n",
        "    for player in [\"X\", \"O\"]:\n",
        "        if (state[0:3] == 3*player):\n",
        "            winner = player\n",
        "        elif (state[3:6] == 3*player):\n",
        "            winner = player\n",
        "        elif (state[6:9] == 3*player):\n",
        "            winner = player\n",
        "        elif (state[0] == player and state[3] == player and state[6] == player):\n",
        "            winner = player\n",
        "        elif (state[1] == player and state[4] == player and state[7] == player):\n",
        "            winner = player\n",
        "        elif (state[2] == player and state[5] == player and state[8] == player):\n",
        "            winner = player\n",
        "        elif (state[0] == player and state[4] == player and state[8] == player):\n",
        "            winner = player\n",
        "        elif (state[2] == player and state[4] == player and state[6] == player):\n",
        "            winner = player\n",
        "\n",
        "    if (winner == \"X\"):\n",
        "      return True, (10, -10)\n",
        "    elif (winner == \"O\"):\n",
        "      return True, (-10, 10)\n",
        "    elif (\"-\" not in self.hash()):\n",
        "      return True, (0, 0)\n",
        "    else:\n",
        "      return False, (0, 0)\n",
        "\n",
        "  def step(self, action, player):\n",
        "\n",
        "    self.state[action//3][action%3] = player\n",
        "\n",
        "    done, reward = self.check_done(self.hash())\n",
        "\n",
        "    return self.hash(), reward, done, {}\n",
        "\n",
        "  def reset(self):\n",
        "    self.state = [\n",
        "        [\"-\",\"-\",\"-\"],\n",
        "        [\"-\",\"-\",\"-\"],\n",
        "        [\"-\",\"-\",\"-\"]\n",
        "        ]\n",
        "\n",
        "\n",
        "  def render(self, mode='human'):\n",
        "    print(\"Board\")\n",
        "    for row in self.state:\n",
        "      print(row)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = TicTacToeEnv()"
      ],
      "metadata": {
        "id": "kfAH9UU3hHeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env.state"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naAo2eyLhZVU",
        "outputId": "0a80664d-5598-4f4d-8799-4ab20e267480"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['-', '-', '-'], ['-', '-', '-'], ['-', '-', '-']]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.hash()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Dlq51kamhaVe",
        "outputId": "bf117e3e-c225-4616-99f1-b2c89dfbb878"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'---------'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_state, reward, done, info = env.step(0, \"X\")"
      ],
      "metadata": {
        "id": "Tlx8JAPEhdgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_state"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vh3MzDhIhfYJ",
        "outputId": "0f98714c-7bb0-4516-8a80-543a97240971"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'X--------'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reward"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HaLLOM3hfxq",
        "outputId": "8606d8c3-026c-404d-9b10-9849dda8987c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 0)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.render()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfWKmnuYhiOv",
        "outputId": "6b59b005-c9ff-4956-836e-28c9a50dffcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Board\n",
            "['X', '-', '-']\n",
            "['-', '-', '-']\n",
            "['-', '-', '-']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.available_actions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gf-J2xXghkRV",
        "outputId": "22ab58fb-86b2-492c-e9fe-0a3417b7c176"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5, 6, 7, 8]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.reset()\n",
        "env.render()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVCtewcRhmRo",
        "outputId": "413e4b30-e499-4858-944f-8eba2d553b2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Board\n",
            "['-', '-', '-']\n",
            "['-', '-', '-']\n",
            "['-', '-', '-']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# variable to keep track of if the game is over\n",
        "done = False\n",
        "# Good practice to reset environment before you play a game to clear any old game\n",
        "env.reset()\n",
        "# Print the initial board\n",
        "env.render()\n",
        "# Want to keep playing untill game is over\n",
        "while not done:\n",
        "    # Make a random action from the list of available actions for X\n",
        "    new_state, reward, done, info = env.step(random.choice(env.available_actions()), \"X\")\n",
        "    # Print board after X action\n",
        "    env.render()\n",
        "\n",
        "    # If the game is done on X action we dont want O to make an action\n",
        "    if not done:\n",
        "        # Make a random action from the list of available actions for O\n",
        "        new_state, reward, done, info = env.step(random.choice(env.available_actions()), \"O\")\n",
        "        # Print board after O action\n",
        "        env.render()\n",
        "\n",
        "# Print the reward after the game is done, reward for X is the first value and O is the second value\n",
        "print(reward)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GakUIlWBhoUR",
        "outputId": "495050a9-de95-495e-afef-be449f151e8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Board\n",
            "['-', '-', '-']\n",
            "['-', '-', '-']\n",
            "['-', '-', '-']\n",
            "Board\n",
            "['-', '-', 'X']\n",
            "['-', '-', '-']\n",
            "['-', '-', '-']\n",
            "Board\n",
            "['O', '-', 'X']\n",
            "['-', '-', '-']\n",
            "['-', '-', '-']\n",
            "Board\n",
            "['O', '-', 'X']\n",
            "['-', '-', '-']\n",
            "['-', 'X', '-']\n",
            "Board\n",
            "['O', '-', 'X']\n",
            "['-', '-', 'O']\n",
            "['-', 'X', '-']\n",
            "Board\n",
            "['O', '-', 'X']\n",
            "['-', 'X', 'O']\n",
            "['-', 'X', '-']\n",
            "Board\n",
            "['O', '-', 'X']\n",
            "['-', 'X', 'O']\n",
            "['-', 'X', 'O']\n",
            "Board\n",
            "['O', '-', 'X']\n",
            "['-', 'X', 'O']\n",
            "['X', 'X', 'O']\n",
            "(10, -10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# variable to keep track of if the game is over\n",
        "done = False\n",
        "# Good practice to reset environment before you play a game to clear any old game\n",
        "env.reset()\n",
        "# Want to keep playing untill game is over\n",
        "while not done:\n",
        "    # Make a random action from the list of available actions for X\n",
        "    new_state, reward, done, info = env.step(random.choice(env.available_actions()), \"X\")\n",
        "    # Print state\n",
        "    print(env.hash())\n",
        "\n",
        "    # If the game is done on X action we dont want O to make an action\n",
        "    if not done:\n",
        "        # Make a random action from the list of available actions for O\n",
        "        new_state, reward, done, info = env.step(random.choice(env.available_actions()), \"O\")\n",
        "        # Print state\n",
        "        print(env.hash())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOq_ZcFohq-2",
        "outputId": "53b8bc53-9156-4692-ac02-713862bd265f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------X-\n",
            "---O---X-\n",
            "-X-O---X-\n",
            "-X-O--OX-\n",
            "-XXO--OX-\n",
            "-XXO--OXO\n",
            "XXXO--OXO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.reset()\n",
        "env.render()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLNf6gg1hvsy",
        "outputId": "a3f175df-7203-47ce-c37b-2e2f658df491"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Board\n",
            "['-', '-', '-']\n",
            "['-', '-', '-']\n",
            "['-', '-', '-']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reward"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNwakcf0hxT8",
        "outputId": "64cbe402-5aff-4850-bc4b-601d1c53d21e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, -10)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.available_actions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-4W6oCxh-PH",
        "outputId": "d18e115a-f3f8-4e4e-da01-d5dd9d54faff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4, 5, 6, 7, 8]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent():\n",
        "\n",
        "    def __init__(self, env, player=\"X\", alpha=.4, gamma=.9):\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.env = env\n",
        "        self.player = player\n",
        "        self.player_number = 0 if player == \"X\" else 1\n",
        "        self.V = {}"
      ],
      "metadata": {
        "id": "ojncGA2Qhyd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent(Agent):\n",
        "\n",
        "    def select_action(self, epsilon=.1):\n",
        "        # generates random number between 0 and 1 if it is below epsilon we take random action otherwise a greedy action\n",
        "        if (random.random() < epsilon):\n",
        "            # gets a random action from list of available actions\n",
        "            action = random.choice(self.env.available_actions())\n",
        "        else:\n",
        "            # list to store action calculations\n",
        "            q_values = []\n",
        "            # loops through the list of available states and rewards\n",
        "            for state in self.env.available_states(self.player):\n",
        "                # calculates gamma*V(S') + Reward for the state\n",
        "                # example: state = ((\"X--O-----\"), (0,0))\n",
        "                q_values.append(self.gamma*self.V[state[0]] + state[1][self.player_number])\n",
        "            # find the max value of the action calculations\n",
        "            max_value = max(q_values)\n",
        "            # selects indexs of values in q_values that are the max_value\n",
        "            max_indexs = [i for i, j in enumerate(q_values) if j == max_value]\n",
        "            # select a random action from the actions that all have the max_value\n",
        "            action = self.env.available_actions()[random.choice(max_indexs)]\n",
        "        return action\n",
        "\n",
        "    def add_states(self):\n",
        "        # adds current state to state value function\n",
        "        if (self.env.hash() not in self.V):\n",
        "            self.V[self.env.hash()] = 0\n",
        "        # adds all states X can get to\n",
        "        for state in self.env.available_states(\"X\"):\n",
        "            if (state[0] not in self.V):\n",
        "                self.V[state[0]] = 0\n",
        "        # adds all states O can get to\n",
        "        for state in self.env.available_states(\"O\"):\n",
        "            if (state[0] not in self.V):\n",
        "                self.V[state[0]] = 0\n",
        "\n",
        "\n",
        "    def update_state_values(self, new_state, old_state, reward):\n",
        "        # V(S) = V(S) + alpha*(R + gamma*(V(S') - V(S)))\n",
        "        self.V[old_state] = self.V[old_state] + self.alpha*(reward + self.gamma*self.V[new_state] - self.V[old_state])"
      ],
      "metadata": {
        "id": "pH851mjLh5bq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of games (episodes)\n",
        "def train(episodes):\n",
        "    # create our agents\n",
        "    agent_x = Agent(env, \"X\")\n",
        "    agent_o = Agent(env, \"O\")\n",
        "    # loops for a certain number of games (episodes)\n",
        "    for episode in range(episodes):\n",
        "        # stops while loop when game is done\n",
        "        done = False\n",
        "        # resets environment when game is done\n",
        "        env.reset()\n",
        "        # while loop for a single game\n",
        "        while not done:\n",
        "\n",
        "            # X agents turn\n",
        "\n",
        "            # adds states for both agents\n",
        "            agent_x.add_states()\n",
        "            agent_o.add_states()\n",
        "\n",
        "            # records the state we are in before action\n",
        "            old_state = env.hash()\n",
        "            # get an action using policy\n",
        "            action = agent_x.select_action()\n",
        "            # performs an action\n",
        "            new_state, reward, done, _ = env.step(action, agent_x.player)\n",
        "\n",
        "            # update state values for both agents\n",
        "            agent_x.update_state_values(new_state, old_state, reward[agent_x.player_number])\n",
        "            agent_o.update_state_values(new_state, old_state, reward[agent_o.player_number])\n",
        "\n",
        "            # if the game ends on X move, we don't want to make an O move\n",
        "            if not done:\n",
        "\n",
        "                # O agents turn\n",
        "\n",
        "                # adds states for both agents\n",
        "                agent_x.add_states()\n",
        "                agent_o.add_states()\n",
        "\n",
        "                # records the state we are in before action\n",
        "                old_state = env.hash()\n",
        "                # get an action using policy\n",
        "                action = agent_o.select_action()\n",
        "                # performs an action\n",
        "                new_state, reward, done, _ = env.step(action, agent_o.player)\n",
        "\n",
        "                # update state values for both agents\n",
        "                agent_x.update_state_values(new_state, old_state, reward[agent_x.player_number])\n",
        "                agent_o.update_state_values(new_state, old_state, reward[agent_o.player_number])\n",
        "\n",
        "    return agent_x, agent_o"
      ],
      "metadata": {
        "id": "5OcT8UqoiQgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "agent_x, agent_o = train(110000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50-SUXByiSR0",
        "outputId": "eb24241b-f011-400d-d4e3-6d3509160385"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2min 38s, sys: 435 ms, total: 2min 39s\n",
            "Wall time: 2min 41s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# number of games (episodes)\n",
        "def test_x(episodes):\n",
        "    # counters to keep track of results\n",
        "    win = 0\n",
        "    tie = 0\n",
        "    loss = 0\n",
        "    # loops for a certain number of games (episodes)\n",
        "    for episode in range(episodes):\n",
        "        # stops while loop when game is done\n",
        "        done = False\n",
        "        # resets environment when game is done\n",
        "        env.reset()\n",
        "        while not done:\n",
        "\n",
        "            # adds states for X only because we are acting randomly and not updating state values for O\n",
        "            agent_x.add_states()\n",
        "\n",
        "            # always get the best action\n",
        "            x_action = agent_x.select_action(epsilon=0)\n",
        "            # performs an action\n",
        "            new_state, reward, done, _ = env.step(x_action, agent_x.player)\n",
        "\n",
        "            # if the game ends on X move, we don't want to make an O move\n",
        "            if (not done):\n",
        "\n",
        "                # O agents turn\n",
        "\n",
        "                # adds states for X only because we are acting randomly and not updating state values for O\n",
        "                agent_x.add_states()\n",
        "\n",
        "                # O always makes a random action from the available actions\n",
        "                o_action = random.choice(env.available_actions())\n",
        "                new_state, reward, done, _ = env.step(o_action, \"O\")\n",
        "\n",
        "        # record results when game is done\n",
        "        if (reward == (10, -10)):\n",
        "            win+=1\n",
        "        elif (reward == (-10, 10)):\n",
        "            loss+=1\n",
        "        elif (reward == (0, 0)):\n",
        "            tie+=1\n",
        "    return win, loss, tie"
      ],
      "metadata": {
        "id": "tRpHr_YtiTuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "episodes = 10000\n",
        "\n",
        "win, loss, tie = test_x(episodes)\n",
        "\n",
        "print(\"Win:\", win, \"Tie:\", tie, \"Loss:\", loss)\n",
        "print(\"Win Rate:\", win/episodes*100, \"Tie Rate:\", tie/episodes*100, \"Loss Rate:\", loss/episodes*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUqw80r9iVZg",
        "outputId": "777b1d6f-12c6-43f5-f11c-ca5a2a0cc05a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Win: 9648 Tie: 352 Loss: 0\n",
            "Win Rate: 96.48 Tie Rate: 3.52 Loss Rate: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "episodes = 110000\n",
        "\n",
        "win, loss, tie = test_x(episodes)\n",
        "\n",
        "print(\"Win:\", win, \"Tie:\", tie, \"Loss:\", loss)\n",
        "print(\"Win Rate:\", win/episodes*100, \"Tie Rate:\", tie/episodes*100, \"Loss Rate:\", loss/episodes*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-nNUoxzJUKT",
        "outputId": "3fbbe1b1-ff31-47da-b319-a1acd257dd70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Win: 105991 Tie: 4009 Loss: 0\n",
            "Win Rate: 96.35545454545455 Tie Rate: 3.6445454545454545 Loss Rate: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# number of games (episodes)\n",
        "def test_o(episodes):\n",
        "    # counters to keep track of results\n",
        "    win = 0\n",
        "    tie = 0\n",
        "    loss = 0\n",
        "    # loops for a certain number of games (episodes)\n",
        "    for episode in range(episodes):\n",
        "        # stops while loop when game is done\n",
        "        done = False\n",
        "        # resets environment when game is done\n",
        "        env.reset()\n",
        "        while not done:\n",
        "\n",
        "            # adds states for O only because we are acting randomly and not updating state values for X\n",
        "            agent_o.add_states()\n",
        "\n",
        "            # X always makes a random action from the available actions\n",
        "            x_action = random.choice(env.available_actions())\n",
        "            # performs an action\n",
        "            new_state, reward, done, _ = env.step(x_action, \"X\")\n",
        "\n",
        "            # if the game ends on X move, we don't want to make an O move\n",
        "            if (not done):\n",
        "\n",
        "                # O agents turn\n",
        "\n",
        "                # adds states for O only because we are acting randomly and not updating state values for X\n",
        "                agent_o.add_states()\n",
        "\n",
        "                # always get the best action\n",
        "                o_action = agent_o.select_action(epsilon=0)\n",
        "                new_state, reward, done, _ = env.step(o_action, agent_o.player)\n",
        "\n",
        "        # record results when game is done\n",
        "        if (reward == (-10, 10)):\n",
        "            win+=1\n",
        "        elif (reward == (10, -10)):\n",
        "            loss+=1\n",
        "        elif (reward == (0, 0)):\n",
        "            tie+=1\n",
        "    return win, loss, tie"
      ],
      "metadata": {
        "id": "0k61sXXeiWZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "episodes = 10000\n",
        "\n",
        "win, loss, tie = test_o(episodes)\n",
        "\n",
        "print(\"Win:\", win, \"Tie:\", tie, \"Loss:\", loss)\n",
        "print(\"Win Rate:\", win/episodes*100, \"Tie Rate:\", tie/episodes*100, \"Loss Rate:\", loss/episodes*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BptBXR24iXyt",
        "outputId": "05383436-269d-4a92-821f-937f09697696"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Win: 8862 Tie: 1138 Loss: 0\n",
            "Win Rate: 88.62 Tie Rate: 11.379999999999999 Loss Rate: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# number of games (episodes)\n",
        "def test(episodes):\n",
        "    # counters to keep track of results\n",
        "    x_win = 0\n",
        "    o_win = 0\n",
        "    tie = 0\n",
        "    # loops for a certain number of games (episodes)\n",
        "    for episode in range(episodes):\n",
        "        # stops while loop when game is done\n",
        "        done = False\n",
        "        # resets environment when game is done\n",
        "        env.reset()\n",
        "        while not done:\n",
        "\n",
        "            # adds states for both agents because we are using select_action on both\n",
        "            agent_x.add_states()\n",
        "            agent_o.add_states()\n",
        "\n",
        "            # always get the best action\n",
        "            x_action = agent_x.select_action(epsilon=0)\n",
        "            # performs an action\n",
        "            new_state, reward, done, _ = env.step(x_action, \"X\")\n",
        "\n",
        "            # if the game ends on X move, we don't want to make an O move\n",
        "            if (not done):\n",
        "\n",
        "                # O agents turn\n",
        "\n",
        "                # adds states for both agents because we are using select_action on both\n",
        "                agent_x.add_states()\n",
        "                agent_o.add_states()\n",
        "\n",
        "                # always get the best action\n",
        "                o_action = agent_o.select_action(epsilon=0)\n",
        "                new_state, reward, done, _ = env.step(o_action, \"O\")\n",
        "\n",
        "        # record results when game is done\n",
        "        if (reward == (-10, 10)):\n",
        "            o_win+=1\n",
        "        elif (reward == (10, -10)):\n",
        "            x_win+=1\n",
        "        elif (reward == (0, 0)):\n",
        "            tie+=1\n",
        "    return x_win, o_win, tie"
      ],
      "metadata": {
        "id": "Kbq4X4ouiZIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "episodes = 10000\n",
        "\n",
        "x_win, o_win, tie = test(episodes)\n",
        "\n",
        "print(\"X Win:\", x_win, \"Tie:\", tie, \"O Win:\", o_win)\n",
        "print(\"X Win Rate:\", x_win/episodes*100, \"Tie Rate:\", tie/episodes*100, \"O Win Rate:\", o_win/episodes*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3N1ACQ4iabf",
        "outputId": "d2f30c48-458d-4f32-93fc-ce3cd9e6b5a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X Win: 0 Tie: 10000 O Win: 0\n",
            "X Win Rate: 0.0 Tie Rate: 100.0 O Win Rate: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# number of games (episodes)\n",
        "def play_as_x(episodes=1):\n",
        "    # counters to keep track of results\n",
        "    x_win = 0\n",
        "    o_win = 0\n",
        "    tie = 0\n",
        "    # loops for a certain number of games (episodes)\n",
        "    for episode in range(episodes):\n",
        "        # stops while loop when game is done\n",
        "        done = False\n",
        "        # resets environment when game is done\n",
        "        env.reset()\n",
        "        while not done:\n",
        "\n",
        "            # print the environment before you go\n",
        "            env.render()\n",
        "            # print available actions\n",
        "            print(env.available_actions())\n",
        "\n",
        "            # adds states for O only because we are controlling X\n",
        "            agent_o.add_states()\n",
        "\n",
        "            # get user input\n",
        "            x_action = int(input())\n",
        "            # performs an action\n",
        "            new_state, reward, done, _ = env.step(x_action, \"X\")\n",
        "\n",
        "            # if the game ends on X move, we don't want to make an O move\n",
        "            if (not done):\n",
        "\n",
        "                # O agents turn\n",
        "\n",
        "                # adds states for O only because we are controlling X\n",
        "                agent_o.add_states()\n",
        "\n",
        "                # always get the best action\n",
        "                o_action = agent_o.select_action(epsilon=0)\n",
        "                new_state, reward, done, _ = env.step(o_action, \"O\")\n",
        "\n",
        "        env.render()\n",
        "        # record results when game is done\n",
        "        if (reward == (-10, 10)):\n",
        "            print(\"You Lose\")\n",
        "        elif (reward == (10, -10)):\n",
        "            print(\"You Win\")\n",
        "        elif (reward == (0, 0)):\n",
        "            print(\"Tie\")"
      ],
      "metadata": {
        "id": "p2cLRPlLib81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "play_as_x()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzUCVFbwidf4",
        "outputId": "801a8dd5-fb40-4598-9826-875c6328dcb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Board\n",
            "['-', '-', '-']\n",
            "['-', '-', '-']\n",
            "['-', '-', '-']\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
            "0\n",
            "Board\n",
            "['X', '-', '-']\n",
            "['-', 'O', '-']\n",
            "['-', '-', '-']\n",
            "[1, 2, 3, 5, 6, 7, 8]\n",
            "8\n",
            "Board\n",
            "['X', '-', '-']\n",
            "['-', 'O', 'O']\n",
            "['-', '-', 'X']\n",
            "[1, 2, 3, 6, 7]\n",
            "3\n",
            "Board\n",
            "['X', '-', '-']\n",
            "['X', 'O', 'O']\n",
            "['O', '-', 'X']\n",
            "[1, 2, 7]\n",
            "2\n",
            "Board\n",
            "['X', 'O', 'X']\n",
            "['X', 'O', 'O']\n",
            "['O', '-', 'X']\n",
            "[7]\n",
            "8\n",
            "Board\n",
            "['X', 'O', 'X']\n",
            "['X', 'O', 'O']\n",
            "['O', 'O', 'X']\n",
            "You Lose\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# number of games (episodes)\n",
        "def play_as_o(episodes=1):\n",
        "    # counters to keep track of results\n",
        "    x_win = 0\n",
        "    o_win = 0\n",
        "    tie = 0\n",
        "    # loops for a certain number of games (episodes)\n",
        "    for episode in range(episodes):\n",
        "        # stops while loop when game is done\n",
        "        done = False\n",
        "        # resets environment when game is done\n",
        "        env.reset()\n",
        "        while not done:\n",
        "\n",
        "            # adds states for X only because we are controlling O\n",
        "            agent_x.add_states()\n",
        "\n",
        "            # always get the best action\n",
        "            x_action = agent_x.select_action(epsilon=0)\n",
        "            # performs an action\n",
        "            new_state, reward, done, _ = env.step(x_action, \"X\")\n",
        "\n",
        "            # if the game ends on X move, we don't want to make an O move\n",
        "            if (not done):\n",
        "\n",
        "                # O agents turn\n",
        "\n",
        "                # print the environment before you go\n",
        "                env.render()\n",
        "                # print available actions\n",
        "                print(env.available_actions())\n",
        "\n",
        "                # adds states for X only because we are controlling O\n",
        "                agent_x.add_states()\n",
        "\n",
        "                # get user input\n",
        "                o_action = int(input())\n",
        "                new_state, reward, done, _ = env.step(o_action, \"O\")\n",
        "\n",
        "        env.render()\n",
        "        # record results when game is done\n",
        "        if (reward == (-10, 10)):\n",
        "            print(\"You Win\")\n",
        "        elif (reward == (10, -10)):\n",
        "            print(\"You Lose\")\n",
        "        elif (reward == (0, 0)):\n",
        "            print(\"Tie\")"
      ],
      "metadata": {
        "id": "FJhjfFB3ievs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "play_as_o()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xg0cD_mjigCd",
        "outputId": "e4408532-e8b3-4b23-91bc-458d7cab3f49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Board\n",
            "['-', '-', '-']\n",
            "['-', 'X', '-']\n",
            "['-', '-', '-']\n",
            "[0, 1, 2, 3, 5, 6, 7, 8]\n",
            "4\n",
            "Board\n",
            "['-', '-', '-']\n",
            "['-', 'O', '-']\n",
            "['-', '-', 'X']\n",
            "[0, 1, 2, 3, 5, 6, 7]\n",
            "0\n",
            "Board\n",
            "['O', '-', 'X']\n",
            "['-', 'O', '-']\n",
            "['-', '-', 'X']\n",
            "[1, 3, 5, 6, 7]\n",
            "1\n",
            "Board\n",
            "['O', 'O', 'X']\n",
            "['-', 'O', 'X']\n",
            "['-', '-', 'X']\n",
            "You Lose\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "episodes = 10000\n",
        "\n",
        "win, loss, tie = test_o(episodes)\n",
        "\n",
        "print(\"Win:\", win, \"Tie:\", tie, \"Loss:\", loss)\n",
        "print(\"Win Rate:\", win/episodes*100, \"Tie Rate:\", tie/episodes*100, \"Loss Rate:\", loss/episodes*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jzpmPvZinvF",
        "outputId": "7df5d62a-a87d-4a54-fa9a-db9a4f2bbd8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Win: 8861 Tie: 1139 Loss: 0\n",
            "Win Rate: 88.61 Tie Rate: 11.39 Loss Rate: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NsqIGNHSiopE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}